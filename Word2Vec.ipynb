{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gXTriBZPoXB"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y-oKTX7PtHG"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfqonRI287cG"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wEIeGNPxlK"
      },
      "source": [
        "##Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVLUnkm0P4BC"
      },
      "source": [
        "###Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1TQNECf9LbS",
        "outputId": "46d41cbf-6aa7-4644-fb2a-97caccf87b00"
      },
      "source": [
        "text = list(pd.read_csv('/content/in_domain_train.tsv', sep='\\t', header=None)[3]) + list(pd.read_csv('/content/in_domain_dev.tsv', sep='\\t', header=None)[3]) + list(pd.read_csv('/content/out_of_domain_dev.tsv', sep='\\t', header=None)[3])\n",
        "text[-10: -1]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John thinks it would upset himself to die.',\n",
              " 'John made Bill mad at himself.',\n",
              " 'John made Bill master of himself.',\n",
              " 'The correspondence school made Bill a good typist.',\n",
              " 'The correspondence school sent Bill a good typist.',\n",
              " 'John considers Bill silly.',\n",
              " 'John considers Bill to be silly.',\n",
              " 'John bought a dog for himself to play with.',\n",
              " 'John arranged for himself to get the prize.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSFp8oHTDTKs",
        "outputId": "fdb39f57-58b4-46ed-8fb4-ae0e263ef5b2"
      },
      "source": [
        "print(len(text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w14OJ_5DP_yC"
      },
      "source": [
        "###Preprocess Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kf3Ki0QAvH1",
        "outputId": "fcf998ef-0890-46de-bc16-e8764a131286"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text)\n",
        "tokenized_text = tokenizer.texts_to_sequences(text)\n",
        "len(tokenized_text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9594"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSJv_ZqsCxgW",
        "outputId": "c9920218-fcda-4fc5-b6a5-682fdad87beb"
      },
      "source": [
        "idx_word = {v: k for k, v in tokenizer.word_index.items()}\n",
        "print(idx_word)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX5igGe8HHft",
        "outputId": "8b8d7cf0-a9e2-4ee9-b096-b78036b4b63f"
      },
      "source": [
        "# Making Sure That Every Element Has length > 1\n",
        "for ele in tokenized_text:\n",
        "    if len(ele) <= 1:\n",
        "        print(ele)\n",
        "        tokenized_text.remove(ele)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKVi2HJsC-Hk",
        "outputId": "8c433903-8ef2-4c09-dba8-9807fc07ffdc"
      },
      "source": [
        "# Randomly Picking The Missing Word(Output) and Using the rest of the Sentence as the Input.\n",
        "# Using each sentence thrice\n",
        "outputs = []\n",
        "inputs = []\n",
        "for i in range(len(tokenized_text)):\n",
        "    seq1 = list(tokenized_text[i])\n",
        "    seq2 = list(tokenized_text[i])\n",
        "    seq3 = list(tokenized_text[i])\n",
        "    ele1 = random.choice(seq1)\n",
        "    ele2 = random.choice(seq2)\n",
        "    ele3 = random.choice(seq3)\n",
        "    outputs.append(ele1)\n",
        "    outputs.append(ele2)\n",
        "    outputs.append(ele3)\n",
        "    seq1.remove(ele1)\n",
        "    seq2.remove(ele2)\n",
        "    seq3.remove(ele3)\n",
        "    inputs.append(seq1)\n",
        "    inputs.append(seq2)\n",
        "    inputs.append(seq3)\n",
        "\n",
        "idx = 2\n",
        "print(inputs[idx])\n",
        "print(outputs[idx])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[204, 289, 232, 163, 28, 777, 778, 1251, 779, 72, 25, 3828]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ftkwkxURFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c3e4fd-9479-4f01-a300-7c8625abf827"
      },
      "source": [
        "inp_padded = pad_sequences(inputs)\n",
        "inp_padded.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28782, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBZgq-0ZQHh7"
      },
      "source": [
        "#Build and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKuJw9mvpU9l"
      },
      "source": [
        "depth = int(list(tokenizer.word_index.values())[-1] + 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qq-aqhMQNLy"
      },
      "source": [
        "##Custom Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3SDQKODoLa2"
      },
      "source": [
        "class PreprocessLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, depth):\n",
        "        super(PreprocessLayer, self).__init__()\n",
        "        self.depth = depth\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        inp_one_hot = tf.one_hot(inputs, depth=self.depth)\n",
        "\n",
        "        return inp_one_hot, inputs\n",
        "\n",
        "class AveragePoolingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, ignore=0):\n",
        "        super(AveragePoolingLayer, self).__init__()\n",
        "        self.ignore = ignore\n",
        "    \n",
        "    def call(self, inp_one_hot, inp_padded):\n",
        "        inp_pad_mask = tf.cast((inp_padded != self.ignore), tf.float64)\n",
        "        inp_mask_sum = tf.math.reduce_sum(inp_pad_mask, axis=-1)\n",
        "        inp_one_hot_1 = inp_one_hot  * tf.expand_dims(inp_pad_mask, axis=-1)\n",
        "        inp_one_hot_avg = tf.math.reduce_sum(inp_one_hot_1, axis=1) / tf.expand_dims(inp_mask_sum, axis=-1)\n",
        "\n",
        "        return inp_one_hot_avg\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-zzyx4CQgeZ"
      },
      "source": [
        "##Initialize The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGHkuToUpdGO"
      },
      "source": [
        "DenseLayer1 = tf.keras.layers.Dense(256, activation='relu')\n",
        "DenseLayer2 = tf.keras.layers.Dense(depth, activation='softmax')\n",
        "model_inp = tf.keras.layers.Input(shape=(41,), dtype=tf.int32)\n",
        "one_hot_inp, padded_inp = PreprocessLayer(depth=depth)(model_inp)\n",
        "x = AveragePoolingLayer()(one_hot_inp, padded_inp)\n",
        "x = DenseLayer1(x)\n",
        "model_out = DenseLayer2(x)\n",
        "model = tf.keras.Model(inputs=model_inp, outputs=model_out)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY5Dj3_mQqfZ"
      },
      "source": [
        "##Train The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBU3GV7nZIp7",
        "outputId": "4311df87-4310-4d84-fce6-fd2d97d68faf"
      },
      "source": [
        "model.fit(inp_padded, np.array(outputs), epochs=40)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "900/900 [==============================] - 10s 8ms/step - loss: 6.7742 - accuracy: 0.0861\n",
            "Epoch 2/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 6.2012 - accuracy: 0.0879\n",
            "Epoch 3/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 5.9079 - accuracy: 0.1039\n",
            "Epoch 4/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 5.5292 - accuracy: 0.1311\n",
            "Epoch 5/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 5.0474 - accuracy: 0.1791\n",
            "Epoch 6/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 4.4919 - accuracy: 0.2407\n",
            "Epoch 7/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 3.8969 - accuracy: 0.3081\n",
            "Epoch 8/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 3.3010 - accuracy: 0.3804\n",
            "Epoch 9/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 2.7437 - accuracy: 0.4589\n",
            "Epoch 10/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 2.2596 - accuracy: 0.5340\n",
            "Epoch 11/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 1.8693 - accuracy: 0.5921\n",
            "Epoch 12/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 1.5592 - accuracy: 0.6485\n",
            "Epoch 13/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 1.3163 - accuracy: 0.6971\n",
            "Epoch 14/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 1.1249 - accuracy: 0.7433\n",
            "Epoch 15/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.9738 - accuracy: 0.7751\n",
            "Epoch 16/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.8480 - accuracy: 0.8075\n",
            "Epoch 17/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.7416 - accuracy: 0.8316\n",
            "Epoch 18/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.6522 - accuracy: 0.8523\n",
            "Epoch 19/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.5753 - accuracy: 0.8696\n",
            "Epoch 20/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.5092 - accuracy: 0.8864\n",
            "Epoch 21/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.4519 - accuracy: 0.9018\n",
            "Epoch 22/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.4040 - accuracy: 0.9105\n",
            "Epoch 23/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.3611 - accuracy: 0.9204\n",
            "Epoch 24/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.3253 - accuracy: 0.9290\n",
            "Epoch 25/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.2941 - accuracy: 0.9346\n",
            "Epoch 26/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.2664 - accuracy: 0.9409\n",
            "Epoch 27/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.2426 - accuracy: 0.9454\n",
            "Epoch 28/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.2217 - accuracy: 0.9500\n",
            "Epoch 29/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.2060 - accuracy: 0.9529\n",
            "Epoch 30/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1891 - accuracy: 0.9568\n",
            "Epoch 31/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1765 - accuracy: 0.9586\n",
            "Epoch 32/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1644 - accuracy: 0.9604\n",
            "Epoch 33/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1551 - accuracy: 0.9617\n",
            "Epoch 34/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1460 - accuracy: 0.9621\n",
            "Epoch 35/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1377 - accuracy: 0.9647\n",
            "Epoch 36/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1310 - accuracy: 0.9649\n",
            "Epoch 37/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1248 - accuracy: 0.9662\n",
            "Epoch 38/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1192 - accuracy: 0.9667\n",
            "Epoch 39/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1141 - accuracy: 0.9679\n",
            "Epoch 40/40\n",
            "900/900 [==============================] - 7s 8ms/step - loss: 0.1111 - accuracy: 0.9674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38a1eeff50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrY3BfXaWXg6"
      },
      "source": [
        "##Predict using a random sentence\n",
        "This is majorly done to check if the model works decently well on a test example. It is a very simple sanity check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsotSOqSaRdT",
        "outputId": "f86ba294-3df4-478b-b69a-8decf4cff227"
      },
      "source": [
        "def predict(sentence):\n",
        "    tokenized = tokenizer.texts_to_sequences([sentence])\n",
        "    tokenized.append([0] * 41)\n",
        "    tokenized = pad_sequences(tokenized)\n",
        "    out = model.predict(tokenized)[0]\n",
        "    max_out = tf.math.argmax(out)\n",
        "    output = idx_word.get(max_out.numpy(), \"\")\n",
        "    print(output)\n",
        "predict(\"the cat sat on the\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "table\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbhb83dJaEog",
        "outputId": "1f9e3c75-580a-41cf-e606-af06a935084a"
      },
      "source": [
        "predict(\"on sat the cat the\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "table\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMbQxn4KaMOC"
      },
      "source": [
        "We can see that the model predicts the same word even though the order of the words are shuffled. \n",
        "\n",
        "This is because the Continuous Bag Of Words(CBOW) model we use here doesn't care about the order of the words while predicting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc148bbEa0iD"
      },
      "source": [
        "#Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soppobVsa4nT"
      },
      "source": [
        "##Extracting The Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5Q1L9ZAqrQ_",
        "outputId": "2f045b73-60b8-4a65-fdc5-81ab2b7c308c"
      },
      "source": [
        "weight_one = DenseLayer1.get_weights()[0]\n",
        "weight_two = DenseLayer2.get_weights()[0]\n",
        "embeddings = 0.5 * (weight_one + weight_two.T)\n",
        "embeddings.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5828, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45oqydyYbU_b"
      },
      "source": [
        "##Saving The Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-8VQVg8bYWK"
      },
      "source": [
        "###Saving as a .txt File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTTCqkZWzAre"
      },
      "source": [
        "with open(\"/content/word2vecembed.txt\", 'w') as file:\n",
        "    for i in range(len(idx_word)):\n",
        "        file.write(f\"{idx_word[i+1]} {embeddings[i+1]}\")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w_honV8bdiS"
      },
      "source": [
        "###Saving as a .tsv file\n",
        "TSV files are better while saving word embeddings as TSVs are the file types suported in Embedding Projectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg1IKK4F1mxe"
      },
      "source": [
        "import io"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuMUigpJ1Lnl"
      },
      "source": [
        "out_v = io.open('word2vec_embeddings.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('word2vec_vocab.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(list(idx_word.values())):\n",
        "    vec = embeddings[index+1]\n",
        "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "    out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyiHRsq6cQQ0"
      },
      "source": [
        "###Downloading The Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xHR-jVqu28dm",
        "outputId": "de042bd8-70c3-4a68-ec09-faf2e70115dd"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('embeddings.tsv')\n",
        "  files.download('words.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_79e37739-1549-4bf5-b5cb-b92685aeba2e\", \"vectors.tsv\", 17214518)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d9814f10-be42-4140-bd9c-2bdb3085ec65\", \"metadata.tsv\", 43421)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NE5scuXA6NxW",
        "outputId": "742afe07-0954-474b-fb88-7815c9da38a4"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('/content/word2vecembed.txt')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1e9bd695-6108-4390-9390-b2bb0a9f9001\", \"word2vecembed.txt\", 21879318)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
